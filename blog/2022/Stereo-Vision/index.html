<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Streo Vision | Yongyun Song</title> <meta name="author" content="Yongyun Song"/> <meta name="description" content="Characteristics of Stereo Vision"/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/yongyunsong.github.io/assets/css/main.css"> <link rel="canonical" href="https://ertyu116-116.github.io/yongyunsong.github.io/blog/2022/Stereo-Vision/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/yongyunsong.github.io/assets/js/theme.js"></script> <script src="/yongyunsong.github.io/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/yongyunsong.github.io/assets/js/distillpub/template.v2.js"></script> <script src="/yongyunsong.github.io/assets/js/distillpub/transforms.v2.js"></script> <script src="/yongyunsong.github.io/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <d-front-matter> <script async type="text/json">{
      "title": "Streo Vision",
      "description": "Characteristics of Stereo Vision",
      "published": "January 14, 2022",
      "authors": [
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-nav"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/yongyunsong.github.io//"><span class="font-weight-bold">Yongyun </span>Song</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/yongyunsong.github.io/">home</a> </li> <li class="nav-item active"> <a class="nav-link" href="/yongyunsong.github.io/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/yongyunsong.github.io/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/yongyunsong.github.io/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Streo Vision</h1> <p>Characteristics of Stereo Vision</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#methods-of-3d-reconstruction">Methods of 3D reconstruction</a></div> <div><a href="#disparity">Disparity</a></div> <div><a href="#multiple-views">Multiple views</a></div> <div><a href="#stereo-vision">Stereo Vision</a></div> <div><a href="#reference">Reference</a></div> </nav> </d-contents> <ul> <li>3D reconstruction <ul> <li>Shading, focus/defocus, texture, perspective effects, motion, occlusion, stereo</li> </ul> </li> <li>Human stereopsis <ul> <li>fixation, disparity</li> </ul> </li> <li>Multiple views <ul> <li>epipolar geometry</li> </ul> </li> <li>Stereo Vision <ul> <li>geometry of a parallel stereo system</li> <li>correspondence</li> </ul> </li> </ul> <h2 id="methods-of-3d-reconstruction">Methods of 3D reconstruction</h2> <ul> <li> <h3 id="dimensionality-reduction">Dimensionality Reduction</h3> <p>The spatial information is lost while 3D object is projected to 2D. In that case, lengths are lost and angle preservation is lost. Hence, Parallel line are lost but there is a vanishing point where two lines, which was once parallel line, meet together.</p> <p>From this vanishing point, we can find out and track the spatial information lost.</p> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Dimensinality_Reduction-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Dimensinality_Reduction-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Dimensinality_Reduction-1400.webp"></source> <img src="/yongyunsong.github.io/assets/img/Stereo%20Vision/Dimensinality_Reduction.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure1. Dimensinality reduction </div> <ul> <li> <h3 id="structure-from-shadow">Structure from Shadow</h3> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Shape_from_Shading-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Shape_from_Shading-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Shape_from_Shading-1400.webp"></source> <img src="/yongyunsong.github.io/assets/img/Stereo%20Vision/Shape_from_Shading.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure2. Structure from Shadow </div> <ul> <li>Lmertian Reflectance Model for approximating the reflectance property of the diffuse surface</li> </ul> \[Diffuse\; Surface\; Color = \frac{\rho_d}{\pi} *L_i * cos{\theta}\] <p>Light from all points on the surface reaches the viewer (camera). It means we can deduce the 3D surface from intensity and angles.</p> <ul> <li> <h3 id="structure-from-focus">Structure from focus</h3> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Shape_from_Focus-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Shape_from_Focus-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Shape_from_Focus-1400.webp"></source> <img src="/yongyunsong.github.io/assets/img/Stereo%20Vision/Shape_from_Focus.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure3. Structure from focus </div> <p>Despite the same images, we can deduce 3D information while using low-pass filter with different sigma to make images blur or not.</p> <ul> <li> <h3 id="texture">Texture</h3> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Shape_from_Texture-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Shape_from_Texture-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Shape_from_Texture-1400.webp"></source> <img src="/yongyunsong.github.io/assets/img/Stereo%20Vision/Shape_from_Texture.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure4. Structure form Texture </div> <p>We can infer the 3D data while measuring images pattern. e.g. If the white seeds of strawberry is close, it means the distance is close. If the white seeds of strawberry is far, it means the distance is far.</p> <ul> <li> <h3 id="perspective-effects">Perspective effects</h3> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Vanishing_point-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Vanishing_point-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Vanishing_point-1400.webp"></source> <img src="/yongyunsong.github.io/assets/img/Stereo%20Vision/Vanishing_point.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure5. Vanishing point </div> <p>Perspective effect means even paraller line converge on one point while 3D image is prjected to 2D image. We can infer spatial information from vanishing point. the side effect of this method,However, is there is foriegn objects of air and the signal is hard to reach on camera. e.g.) when we take a mountain photo, the more the object is far from the camera, the more ambiguous the object is.</p> <ul> <li> <h3 id="stereo">Stereo</h3> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Stereo_Vision-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Stereo_Vision-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Stereo_Vision-1400.webp"></source> <img src="/yongyunsong.github.io/assets/img/Stereo%20Vision/Stereo_Vision.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure6. Stereo Vision </div> <p>It is important to note that the camera centor should be moved not fixed with rotation in Stereo Vision for obtaining exact 3D information.</p> <h2 id="disparity">Disparity</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Disparity-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Disparity-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Disparity-1400.webp"></source> <img src="/yongyunsong.github.io/assets/img/Stereo%20Vision/Disparity.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure7. Human steropsis: disparity </div> <p>disparity occurs when eyes fixate on one object; others appear at different visual angles. Disparity is distance from b1 to b2 along retina.</p> <h2 id="multiple-views">Multiple views</h2> <p>Why we have multiple views? Because there is distortion when projection occurs. e.g. the line which is connected the optical center of camera is projected to one point, not line.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Multiple_views-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Multiple_views-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Multiple_views-1400.webp"></source> <img src="/yongyunsong.github.io/assets/img/Stereo%20Vision/Multiple_views.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure8. Multiple views </div> <p>In multiple views, we shift the projection image to infront of the optical center than using pin hole model which change the locations for 2D coordinate,as an ideal mathematic method.</p> <h2 id="stereo-vision">Stereo Vision</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Epipolar_Geometry-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Epipolar_Geometry-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/yongyunsong.github.io/assets/img/Stereo%20Vision/Epipolar_Geometry-1400.webp"></source> <img src="/yongyunsong.github.io/assets/img/Stereo%20Vision/Epipolar_Geometry.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure9. Epipolar Geometry </div> <p>epipole - when the line which connects optical centers of two cameras, e and e’ are called to epipoles. epipolar line - the line which connects epipole and point projected. epipolar constraint - Depending on DOF(Degree of Freedom), there are the 8,7,5,3 and 1 pair of matching points to obtain fundamental and essential matrix. Triangulation - If we know E, F matrix and p,p’, we can obtain 3D point.</p> <h2 id="reference">Reference</h2> <ul> <li>https://www.youtube.com/watch?v=3QjEOlfvg9M&amp;t=2326</li> <li>https://math.hws.edu/graphicsbook/c4/s1.html</li> </ul> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Yongyun Song. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <d-bibliography src="/yongyunsong.github.io/assets/bibliography/"></d-bibliography> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-FL4TW18DX5"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-FL4TW18DX5");</script> </body> </html>